* Install Ubuntu 14.04.5LTS in a Virtual Box VM
	Network -> NAT -> Connect cable
	Network -> Enable 2nd NIC -> Host-only -> Connect cable
	General -> Advanced -> Clipboard -> Bidireccional
	Do not download updates while installing (It does not save time as plenty of updates need to be installed anyways after install finishes)
	Do not download 3P software
	Erase disk and install Ubuntu
	administrator / xxxyourpasswordxxx
	Hostname: u1404cdh
Restart

* Software & Updates (DO NOT SKIP THIS STEP)
	Updates -> Uncheck recommended updates, pre-releases y unsupported software.
	Install all updates. 
Restart
	
* Install VBox guest additions
	Download and install in the host machine
	Install in the guest machine (Right control + K)
Restart

* Firefox
	Uncheck Firefox data collection and use.

** Step2: Make password less sudo access
#NOT DONE: sudo adduser `whoami` sudo;
sudo sed -i '/%sudo.*/c\%sudo   ALL=(ALL:ALL) NOPASSWD:ALL' /etc/sudoers;
#NOT DONE: sudo visudo 
#	# User privilege specification
#	root	ALL=(ALL:ALL) ALL
#	# Members of the admin group may gain root privileges
#	%admin ALL=(ALL:ALL) ALL
#	# Allow members of group sudo to execute any command
#	%sudo   ALL=(ALL:ALL) NOPASSWD: ALL	

** Step3: Assignment of static IP address and hostname
# NOT DONE: sudo hostname u1404cdh
# NOT DONE: sudo cat /etc/hostname
# 	u1404cdh
# NOT DONE: sudo gedit /etc/hosts
#	127.0.0.1	localhost
#	127.0.0.1	u1404cdh
sudo sed -i 's/127\.0\.1\.1/127\.0\.0\.1/' /etc/hosts;

** Step4: Installation and Configuration of SSH
sudo apt-get install -y openssh-server
ssh-keygen
	Confirm
ssh-copy-id u1404cdh
	Confirm
#check connection:  
ssh administrator@u1404cdh 'sudo ls -la /etc/hosts'
	
** Step5: 
sudo sysctl vm.swappiness=10 && sudo echo 'vm.swappiness = 10' | sudo tee -a /etc/sysctl.conf;

** Step6: Install Java 8... https://tecadmin.net/install-oracle-java-8-ubuntu-via-ppa/#
sudo add-apt-repository ppa:webupd8team/java
sudo apt-get update
sudo apt-get install oracle-java8-installer
java -version 
	java version "1.8.0_xxx"
sudo apt-get install oracle-java8-set-default
sudo chmod go+w /etc/environment

cat >> /etc/environment <<EOL
JAVA_HOME=/usr/lib/jvm/java-8-oracle
JRE_HOME=/usr/lib/jvm/java-8-oracle/jre
EOL

sudo chmod go-w /etc/environment

** Step7: Setup other dependencies... https://medium.com/@josemarcialportilla/installing-scala-and-spark-on-ubuntu-5665ee4b62b1
** Step 7.1: Install Scala
sudo apt-get install scala
scala
println(“Hello World”)
:q

** Step 7.2: Install Git
sudo apt-get install git

** Step 7.3: Install Spark
sudo mkdir /usr/local/mybigdata
sudo chmod ugo+wr /usr/local/mybigdata/

Go to https://spark.apache.org/downloads.html and download a pre-built for Hadoop 2.7 version of Spark.
cd ~/Downloads
tar xvf spark-2.0.2-bin-hadoop2.7.tgz
mv spark-2.2.0-bin-hadoop2.7 /usr/local/mybigdata/
rm spark-2.2.0-bin-hadoop2.7.tgz

** Step8: Check Spark: 
echo "a b b b c c c c c c c d d d e e e e e e e e e e f f g h i">input.txt
cd /usr/local/mybigdata/spark-2.2.0-bin-hadoop2.7/bin
./spark-shell ##Runs Spark reading from filesystem

val tokenized = sc.textFile("input.txt").flatMap(_.split(" "))
val wordCounts = tokenized.map((_, 1)).reduceByKey(_ + _)
val filtered = wordCounts.filter(_._2 >= 5)
System.out.println(filtered.collect().mkString(", "))
:q

** Step9: Install Hadoop... http://hadoop.apache.org/docs/current/hadoop-project-dist/hadoop-common/SingleCluster.html
sudo apt-get install ssh
sudo apt-get install pdsh
Go to http://www.apache.org/dyn/closer.cgi/hadoop/common/ and download installer.
cd ~/Downloads
tar -xf hadoop-2.8.2.tar.gz 
mv hadoop-2.8.2/ /usr/local/mybigdata/
rm hadoop-2.8.2.tar.gz 

cd ~
mkdir input
cp /usr/local/mybigdata/hadoop-2.8.2/etc/hadoop/*.xml input
#Runs without HDFS and without YARN
/usr/local/mybigdata/hadoop-2.8.2/bin/hadoop jar /usr/local/mybigdata/hadoop-2.8.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar grep input output 'dfs[a-z.]+'
cat output/*

gedit /usr/local/mybigdata/hadoop-2.8.2/etc/hadoop/core-site.xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>

gedit /usr/local/mybigdata/hadoop-2.8.2/etc/hadoop/hdfs-site.xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>

ssh localhost
	yes

mkdir /tmp/hadoop-administrator/dfs/name

cd /usr/local/mybigdata/hadoop-2.8.2/
bin/hdfs namenode -format

sbin/start-dfs.sh
	yes

bin/hdfs dfs -mkdir /user
bin/hdfs dfs -mkdir /user/administrator

bin/hdfs dfs -mkdir input
bin/hdfs dfs -put etc/hadoop/*.xml input
#Runs with HDFS and without YARN
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar grep input output 'dfs[a-z.]+'
bin/hdfs dfs -cat output/*

gedit etc/hadoop/mapred-site.xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>

gedit etc/hadoop/yarn-site.xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.nodemanager.env-whitelist</name>
        <value>JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,HADOOP_YARN_HOME,HADOOP_MAPRED_HOME</value>
    </property>
</configuration>

sbin/start-yarn.sh

http://192.168.56.102:8088/cluster

#Runs with HDFS and with YARN
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.8.2.jar grep input output 'dfs[a-z.]+'

cd /usr/local/mybigdata/spark-2.2.0-bin-hadoop2.7/bin
../../hadoop-2.8.2/bin/hdfs dfs -put bin/input.txt
./spark-shell ##Runs Spark integrated with HDFS

val tokenized = sc.textFile("hdfs://localhost:9000/user/administrator/input.txt").flatMap(_.split(" "))
val wordCounts = tokenized.map((_, 1)).reduceByKey(_ + _)
val filtered = wordCounts.filter(_._2 >= 5)
System.out.println(filtered.collect().mkString(", "))
:q
